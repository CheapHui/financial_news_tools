# å®Œæ•´æ–°èåˆ†ææµæ°´ç·šä½¿ç”¨æŒ‡å—

æˆ‘å·²ç¶“ç‚ºæ‚¨å‰µå»ºäº†ä¸€å€‹å®Œæ•´çš„æ–°èåˆ†ææµæ°´ç·šå‘½ä»¤ï¼Œå¯ä»¥ä¸€æ¬¡åŸ·è¡Œæ‰€æœ‰æ­¥é©Ÿã€‚

## ğŸš€ æµæ°´ç·šæ­¥é©Ÿ

å®Œæ•´æµæ°´ç·šåŒ…å«ä»¥ä¸‹ 6 å€‹æ­¥é©Ÿï¼š

1. **ğŸ“° ingest_rss** - å¾ RSS æºæ”å–æ–°èæ–‡ç« ï¼ˆå¯é¸ï¼‰
2. **ğŸ“Š embed_news** - ç‚ºæ–°èç”ŸæˆåµŒå…¥å‘é‡
3. **ğŸ”— link_news_entities** - é€£çµæ–°èèˆ‡å¯¦é«”ï¼ˆå…¬å¸/è¡Œæ¥­ï¼‰
4. **ğŸ¤– score_news** - ä½¿ç”¨ AI æ¨¡å‹è¨ˆç®—æ–°èåˆ†æ•¸
5. **ğŸ“ˆ rollup_signals** - èšåˆä¿¡è™Ÿåˆ°å…¬å¸å’Œè¡Œæ¥­
6. **ğŸ’¡ build_recommendations** - ç”ŸæˆæŠ•è³‡å»ºè­°

## ğŸ“‹ å¯ç”¨å‘½ä»¤

### Makefile å‘½ä»¤ï¼ˆæ¨è–¦ï¼‰

```bash
# å®Œæ•´æµæ°´ç·šï¼ˆè©³ç´°è¼¸å‡ºï¼‰
make full-pipeline

# å¿«é€Ÿç‰ˆæœ¬ï¼ˆè¼ƒçŸ­æ™‚é–“ç¯„åœï¼‰
make full-pipeline-fast  

# è·³éå»ºè­°ç”Ÿæˆï¼ˆç•¶ç¼ºå°‘ pandas æ™‚ï¼‰
make full-pipeline-skip-reco

# èˆŠçš„å‘½ä»¤åˆ¥å
make recommendations
```

### ç›´æ¥ Django å‘½ä»¤

```bash
cd mytrading

# å®Œæ•´æµæ°´ç·šï¼ˆæ‰€æœ‰æ­¥é©Ÿï¼‰
python manage.py process_news_pipeline --verbose

# è‡ªå®šç¾©åƒæ•¸
python manage.py process_news_pipeline \
  --since-hours 24 \
  --lookback-hours 168 \
  --model deepseek-reasoner \
  --half-life 72 \
  --apply-overall-when-missing \
  --verbose

# è·³éå»ºè­°ç”Ÿæˆ
python manage.py process_news_pipeline \
  --since-hours 24 \
  --skip-recommendations \
  --verbose
```

## âš™ï¸ åƒæ•¸èªªæ˜

### æ–°èæ”å–åƒæ•¸
- `--max-news`: æ¯å€‹RSSæºæœ€å¤šæ”å–æ–°èæ•¸é‡ï¼ˆé»˜èª 40ï¼‰
- `--feed`: æŒ‡å®šRSSæºURLï¼Œå¯å¤šæ¬¡ä½¿ç”¨ï¼ˆé»˜èªä½¿ç”¨å…§å»ºæºï¼‰
- `--allow-langs`: å…è¨±çš„èªè¨€ï¼ˆé»˜èª en,zhï¼‰
- `--skip-ingest`: è·³éæ–°èæ”å–æ­¥é©Ÿ

### æ–°èè™•ç†åƒæ•¸
- `--since-hours`: è™•ç†æœ€è¿‘ N å°æ™‚çš„æ–°èï¼ˆé»˜èª 24ï¼‰
- `--model`: AI æ¨¡å‹åç¨±ï¼ˆé»˜èª deepseek-reasonerï¼‰
- `--half-life`: æ–°èåˆ†æ•¸æ™‚é–“è¡°æ¸›åŠè¡°æœŸï¼Œå°æ™‚ï¼ˆé»˜èª 72ï¼‰
- `--lookback-hours`: ä¿¡è™Ÿèšåˆå›çœ‹æ™‚é–“ï¼Œå°æ™‚ï¼ˆé»˜èª 168ï¼‰
- `--apply-overall-when-missing`: ç•¶ç„¡ç²¾æº–åŒ¹é…æ™‚ä½¿ç”¨æ•´é«”æƒ…æ„Ÿ

### å»ºè­°ç”Ÿæˆåƒæ•¸
- `--benchmark`: åŸºæº–æŒ‡æ•¸ï¼ˆé»˜èª SPYï¼‰
- `--min-cap`: æœ€å°å¸‚å€¼éæ¿¾ï¼ˆé»˜èª 20Bï¼‰
- `--universe-limit`: è‚¡ç¥¨æ± æœ€å¤§æ•¸é‡ï¼ˆé»˜èª 800ï¼‰
- `--rs-threshold`: ç›¸å°å¼·åº¦é–¾å€¼ï¼ˆé»˜èª 70.0ï¼‰
- `--alpha`: æ–°èæ¬Šé‡ä¿‚æ•¸ï¼ˆé»˜èª 0.2ï¼‰
- `--k`: tanh å£“ç¸®ä¿‚æ•¸ï¼ˆé»˜èª 1.0ï¼‰
- `--save-top`: ä¿å­˜å‰ N å€‹å»ºè­°ï¼ˆé»˜èª 200ï¼‰

### æ§åˆ¶é¸é …
- `--skip-recommendations`: è·³éå»ºè­°ç”Ÿæˆæ­¥é©Ÿ
- `--verbose`: é¡¯ç¤ºè©³ç´°è¼¸å‡º

## ğŸ”§ æ•…éšœæ’é™¤

### 1. DeepSeek API è¶…æ™‚éŒ¯èª¤

**éŒ¯èª¤ä¿¡æ¯:**
```
[score_news:skip] id=11 err=HTTPSConnectionPool(host='api.deepseek.com', port=443): Read timed out.
```

**è§£æ±ºæ–¹æ¡ˆ:**

a) **è·³éæ–°èåˆ†æ•¸è¨ˆç®—**ï¼ˆæ¨è–¦ç”¨æ–¼æ¸¬è©¦ï¼‰:
```bash
# åªåŸ·è¡Œå‰å…©æ­¥å’Œå¾Œå…©æ­¥ï¼Œè·³é AI åˆ†æ•¸è¨ˆç®—
python manage.py embed_news --days-back 1
python manage.py link_news_entities --days-back 1  
python manage.py rollup_signals --lookback-hours 24
```

b) **ä½¿ç”¨ä¸åŒçš„ AI æ¨¡å‹**:
```bash
python manage.py process_news_pipeline --model gpt-3.5-turbo --verbose
```

c) **å¢åŠ è¶…æ™‚æ™‚é–“** - éœ€è¦ä¿®æ”¹ `news_scoring.py` ä¸­çš„è¶…æ™‚è¨­å®š

d) **æ‰¹é‡è™•ç†** - æ¸›å°‘ `--since-hours` åƒæ•¸ï¼Œåˆ†æ‰¹è™•ç†æ–°è

### 2. ç¼ºå°‘ pandas/yfinance éŒ¯èª¤

**éŒ¯èª¤ä¿¡æ¯:**
```
ModuleNotFoundError: No module named 'pandas'
```

**è§£æ±ºæ–¹æ¡ˆ:**

a) **å®‰è£ä¾è³´**:
```bash
pip install pandas yfinance
```

b) **è·³éå»ºè­°ç”Ÿæˆ**:
```bash
make full-pipeline-skip-reco
```

### 3. æ²’æœ‰æ–°èæ•¸æ“š

**éŒ¯èª¤ä¿¡æ¯:**
```
No chunks to embed.
Linked entities written: 0
```

**è§£æ±ºæ–¹æ¡ˆ:**

å…ˆæ”å–ä¸€äº›æ–°èæ•¸æ“šï¼š
```bash
make news-ingest  # æ”å–æ–°è
make news-embed   # ç”ŸæˆåµŒå…¥
```

## ğŸ“Š åŸ·è¡ŒçµæœæŸ¥çœ‹

### 1. æª¢æŸ¥ä¿¡è™Ÿæ•¸æ“š

```bash
# æŸ¥çœ‹æ–°èåˆ†æ•¸ä¿¡è™Ÿ
curl http://localhost:8001/api/signals/news-score-summary/ | jq .

# æŸ¥çœ‹ç‰¹å®šå…¬å¸ä¿¡è™Ÿ
curl http://localhost:8001/api/companies/AAPL/news-score-signal/ | jq .
```

### 2. æ•¸æ“šåº«æŸ¥è©¢

```bash
make psql

# æª¢æŸ¥æ–°èåˆ†æ•¸
SELECT COUNT(*) FROM news_newsitem WHERE news_scores_json IS NOT NULL;

# æª¢æŸ¥ä¿¡è™Ÿèšåˆçµæœ
SELECT COUNT(*) FROM research_analyticscompanysignal WHERE window_count > 0;

# æª¢æŸ¥æŠ•è³‡å»ºè­°
SELECT COUNT(*) FROM analytics_analyticsrecommendation;
```

## ğŸ¯ ä½¿ç”¨å»ºè­°

### 1. é¦–æ¬¡é‹è¡Œ

```bash
# ç¢ºä¿æœ‰åŸºç¤æ•¸æ“š
make init-all

# æ”å–ä¸€äº›æ–°è
make news-ingest

# é‹è¡Œå®Œæ•´æµæ°´ç·šï¼ˆè·³éå»ºè­°ç”Ÿæˆï¼‰
make full-pipeline-skip-reco
```

### 2. æ—¥å¸¸é‹è¡Œ

```bash
# æ¯æ—¥æ›´æ–°ï¼ˆåŒ…å«å»ºè­°ç”Ÿæˆï¼‰
make full-pipeline

# æˆ–è€…è¨­ç½® cron ä»»å‹™
0 6 * * * cd /path/to/project && make full-pipeline
```

### 3. å¿«é€Ÿæ¸¬è©¦

```bash
# åªè™•ç†æœ€è¿‘ 1 å°æ™‚çš„æ–°èï¼Œè·³éå»ºè­°
python manage.py process_news_pipeline \
  --since-hours 1 \
  --lookback-hours 24 \
  --skip-recommendations \
  --verbose
```

## ğŸ”„ æµæ°´ç·šæµç¨‹åœ–

```mermaid
graph TD
    A[é–‹å§‹] --> B[embed_news<br/>ç”ŸæˆåµŒå…¥å‘é‡]
    B --> C[link_news_entities<br/>é€£çµå¯¦é«”]
    C --> D[score_news<br/>AIåˆ†æ•¸è¨ˆç®—]
    D --> E[rollup_signals<br/>ä¿¡è™Ÿèšåˆ]
    E --> F[build_recommendations<br/>ç”Ÿæˆå»ºè­°]
    F --> G[å®Œæˆ]
    
    D -.-> H[APIè¶…æ™‚?]
    H -.-> I[è·³éæˆ–é‡è©¦]
    
    F -.-> J[ç¼ºå°‘ä¾è³´?]
    J -.-> K[å®‰è£æˆ–è·³é]
```

## ğŸ“ˆ ç›£æ§å’Œç¶­è­·

### 1. æ€§èƒ½ç›£æ§

```bash
# æŸ¥çœ‹åŸ·è¡Œæ™‚é–“
time make full-pipeline

# ç›£æ§ API ä½¿ç”¨æƒ…æ³
curl http://localhost:8001/api/metrics/summary/
```

### 2. éŒ¯èª¤è™•ç†

æµæ°´ç·šå…·æœ‰å…§å»ºéŒ¯èª¤è™•ç†ï¼š
- æ¯æ­¥é©Ÿç¨ç«‹åŸ·è¡Œï¼Œå¤±æ•—æ™‚åœæ­¢
- æä¾›è©³ç´°éŒ¯èª¤ä¿¡æ¯å’Œå»ºè­°
- æ”¯æ´è·³éæœ‰å•é¡Œçš„æ­¥é©Ÿ

### 3. è‡ªå‹•åŒ–éƒ¨ç½²

```bash
# æ·»åŠ åˆ° crontab
crontab -e

# æ¯å¤©æ—©ä¸Š 6 é»åŸ·è¡Œ
0 6 * * * cd /Users/tobychunyu/Downloads/trading-infra-mvp/backend && make full-pipeline >> /var/log/trading-pipeline.log 2>&1
```

é€™å€‹å®Œæ•´çš„æµæ°´ç·šå‘½ä»¤è®“æ‚¨å¯ä»¥ä¸€æ¬¡åŸ·è¡Œæ‰€æœ‰æ–°èåˆ†ææ­¥é©Ÿï¼Œå¾åŸå§‹æ–°èåˆ°æœ€çµ‚çš„æŠ•è³‡å»ºè­°ï¼
