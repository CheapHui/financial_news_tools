import json
import threading
import time
from datetime import datetime, timezone
from django.http import JsonResponse
from django.views.decorators.http import require_http_methods
from django.views.decorators.csrf import csrf_exempt
from django.core.management import call_command
from django.utils import timezone as django_timezone
import logging

logger = logging.getLogger(__name__)

# å…¨å±€è®Šé‡å­˜å„²æµæ°´ç·šç‹€æ…‹
pipeline_status = {
    "is_running": False,
    "current_step": None,
    "total_steps": 0,
    "completed_steps": 0,
    "start_time": None,
    "end_time": None,
    "error": None,
    "results": {},
    "logs": []
}

def add_log(message, level="INFO"):
    """æ·»åŠ æ—¥èªŒåˆ°ç‹€æ…‹ä¸­"""
    global pipeline_status
    timestamp = datetime.now(timezone.utc).isoformat()
    log_entry = {
        "timestamp": timestamp,
        "level": level,
        "message": message
    }
    pipeline_status["logs"].append(log_entry)
    # ä¿æŒæœ€å¤š 100 æ¢æ—¥èªŒ
    if len(pipeline_status["logs"]) > 100:
        pipeline_status["logs"] = pipeline_status["logs"][-100:]

def run_pipeline_async(params):
    """ç•°æ­¥é‹è¡Œæµæ°´ç·š"""
    global pipeline_status
    
    try:
        pipeline_status["is_running"] = True
        pipeline_status["start_time"] = datetime.now(timezone.utc).isoformat()
        pipeline_status["error"] = None
        pipeline_status["logs"] = []
        pipeline_status["results"] = {}
        
        # è¨ˆç®—ç¸½æ­¥é©Ÿæ•¸
        total_steps = 0
        if not params.get("skip_ingest", False):
            total_steps += 1
        total_steps += 4  # embed + link + score + rollup
        if not params.get("skip_recommendations", False):
            total_steps += 1
        
        pipeline_status["total_steps"] = total_steps
        pipeline_status["completed_steps"] = 0
        
        add_log("ğŸš€ é–‹å§‹åŸ·è¡Œå®Œæ•´æ–°èåˆ†ææµæ°´ç·š")
        
        # æ§‹å»ºå‘½ä»¤åƒæ•¸
        cmd_args = {
            "since_hours": params.get("since_hours", 24),
            "model": params.get("model", "deepseek-reasoner"),
            "half_life": params.get("half_life", 72),
            "lookback_hours": params.get("lookback_hours", 168),
            "verbose": True
        }
        
        # æ–°èæ”å–åƒæ•¸
        if not params.get("skip_ingest", False):
            cmd_args["max_news"] = params.get("max_news", 40)
            cmd_args["allow_langs"] = params.get("allow_langs", "en,zh")
        else:
            cmd_args["skip_ingest"] = True
            
        # å»ºè­°ç”Ÿæˆåƒæ•¸
        if params.get("skip_recommendations", False):
            cmd_args["skip_recommendations"] = True
        else:
            cmd_args.update({
                "benchmark": params.get("benchmark", "SPY"),
                "min_cap": params.get("min_cap", 20e9),
                "universe_limit": params.get("universe_limit", 800),
                "rs_threshold": params.get("rs_threshold", 70.0),
                "alpha": params.get("alpha", 0.2),
                "k": params.get("k", 1.0),
                "save_top": params.get("save_top", 200)
            })
        
        if params.get("apply_overall_when_missing", False):
            cmd_args["apply_overall_when_missing"] = True
        
        add_log(f"åƒæ•¸è¨­å®š: {json.dumps(cmd_args, indent=2, ensure_ascii=False)}")
        
        # åŸ·è¡Œæµæ°´ç·š
        call_command("process_news_pipeline", **cmd_args)
        
        pipeline_status["end_time"] = datetime.now(timezone.utc).isoformat()
        pipeline_status["completed_steps"] = pipeline_status["total_steps"]
        add_log("ğŸ‰ æµæ°´ç·šåŸ·è¡Œå®Œæˆï¼", "SUCCESS")
        
    except Exception as e:
        error_msg = f"æµæ°´ç·šåŸ·è¡Œå¤±æ•—: {str(e)}"
        pipeline_status["error"] = error_msg
        pipeline_status["end_time"] = datetime.now(timezone.utc).isoformat()
        add_log(error_msg, "ERROR")
        logger.exception("Pipeline execution failed")
        
    finally:
        pipeline_status["is_running"] = False

@csrf_exempt
@require_http_methods(["POST"])
def start_pipeline(request):
    """å•Ÿå‹•æµæ°´ç·š"""
    global pipeline_status
    
    if pipeline_status["is_running"]:
        return JsonResponse({
            "success": False,
            "error": "æµæ°´ç·šå·²åœ¨é‹è¡Œä¸­"
        }, status=400)
    
    try:
        # è§£æè«‹æ±‚åƒæ•¸
        if request.content_type == 'application/json':
            params = json.loads(request.body)
        else:
            params = {}
        
        # å•Ÿå‹•ç•°æ­¥åŸ·è¡Œ
        thread = threading.Thread(target=run_pipeline_async, args=(params,))
        thread.daemon = True
        thread.start()
        
        return JsonResponse({
            "success": True,
            "message": "æµæ°´ç·šå·²å•Ÿå‹•"
        })
        
    except Exception as e:
        return JsonResponse({
            "success": False,
            "error": f"å•Ÿå‹•å¤±æ•—: {str(e)}"
        }, status=500)

@require_http_methods(["GET"])
def pipeline_status_api(request):
    """ç²å–æµæ°´ç·šç‹€æ…‹"""
    global pipeline_status
    
    # è¨ˆç®—é€²åº¦ç™¾åˆ†æ¯”
    progress = 0
    if pipeline_status["total_steps"] > 0:
        progress = (pipeline_status["completed_steps"] / pipeline_status["total_steps"]) * 100
    
    # è¨ˆç®—é‹è¡Œæ™‚é–“
    duration = None
    if pipeline_status["start_time"]:
        start = datetime.fromisoformat(pipeline_status["start_time"].replace('Z', '+00:00'))
        end_time = pipeline_status["end_time"]
        if end_time:
            end = datetime.fromisoformat(end_time.replace('Z', '+00:00'))
        else:
            end = datetime.now(timezone.utc)
        duration = int((end - start).total_seconds())
    
    return JsonResponse({
        "is_running": pipeline_status["is_running"],
        "current_step": pipeline_status["current_step"],
        "total_steps": pipeline_status["total_steps"],
        "completed_steps": pipeline_status["completed_steps"],
        "progress": round(progress, 1),
        "start_time": pipeline_status["start_time"],
        "end_time": pipeline_status["end_time"],
        "duration": duration,
        "error": pipeline_status["error"],
        "results": pipeline_status["results"],
        "logs": pipeline_status["logs"][-20:]  # åªè¿”å›æœ€è¿‘ 20 æ¢æ—¥èªŒ
    })

@require_http_methods(["POST"])
def stop_pipeline(request):
    """åœæ­¢æµæ°´ç·šï¼ˆæ³¨æ„ï¼šé€™åªæ˜¯æ¨™è¨˜åœæ­¢ï¼Œå¯¦éš›å‘½ä»¤å¯èƒ½ä»åœ¨é‹è¡Œï¼‰"""
    global pipeline_status
    
    if not pipeline_status["is_running"]:
        return JsonResponse({
            "success": False,
            "error": "æµæ°´ç·šæœªåœ¨é‹è¡Œ"
        }, status=400)
    
    pipeline_status["is_running"] = False
    pipeline_status["error"] = "ç”¨æˆ¶æ‰‹å‹•åœæ­¢"
    pipeline_status["end_time"] = datetime.now(timezone.utc).isoformat()
    add_log("ç”¨æˆ¶æ‰‹å‹•åœæ­¢æµæ°´ç·š", "WARNING")
    
    return JsonResponse({
        "success": True,
        "message": "æµæ°´ç·šå·²åœæ­¢"
    })

@require_http_methods(["POST"])
def clear_pipeline_logs(request):
    """æ¸…é™¤æµæ°´ç·šæ—¥èªŒ"""
    global pipeline_status
    
    pipeline_status["logs"] = []
    
    return JsonResponse({
        "success": True,
        "message": "æ—¥èªŒå·²æ¸…é™¤"
    })
